{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nDLVG_VhF-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k4-c8WlIP5n",
        "colab_type": "text"
      },
      "source": [
        "### Load dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbJSGfcehGDC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "098f852d-594f-49ed-9dd0-4f2e14d887fc"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root='.', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])), batch_size=64, shuffle=True, num_workers=4)\n",
        "# Test dataset\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(root='.', train=False, transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])), batch_size=64, shuffle=True, num_workers=4)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 28447245.09it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 454219.02it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 144109.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7557387.78it/s]                            \n",
            "8192it [00:00, 172219.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIHtRkeFIR27",
        "colab_type": "text"
      },
      "source": [
        "### Define NN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haFMQNt8hGjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 4, 3)\n",
        "    self.conv2 = nn.Conv2d(4, 8, 3)\n",
        "    self.conv3 = nn.Conv2d(8, 16, 3)\n",
        "    self.fc1 = nn.Linear(4608, 100)\n",
        "    self.fc2 = nn.Linear(100, 10)\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    # print('HUY', x.shape)\n",
        "    # x = F.softmax(x, dim=1)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    # We use log_softmax because loss function CrossEntropyLoss expects log_softmax, proof:\n",
        "    # https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss\n",
        "    \n",
        "    # print(x.shape)\n",
        "    # print('HERE!!!', x[0].sum())\n",
        "    return x\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "        num_features *= s\n",
        "    return num_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F82b36OPItPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "481da75b-34a7-42d0-cbb3-adb47e653f78"
      },
      "source": [
        "# Just several examples how softmax and log_softmax work\n",
        "data = torch.tensor([[1.,2,3,4,5, 9], [-100, 10, 2., 5, 6, -10]])\n",
        "print(data)\n",
        "print(F.softmax(data, dim=1))\n",
        "print(F.softmax(data, dim=1).sum())\n",
        "print(F.log_softmax(data, dim=1))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   1.,    2.,    3.,    4.,    5.,    9.],\n",
            "        [-100.,   10.,    2.,    5.,    6.,  -10.]])\n",
            "tensor([[3.2608e-04, 8.8637e-04, 2.4094e-03, 6.5495e-03, 1.7803e-02, 9.7203e-01],\n",
            "        [0.0000e+00, 9.7524e-01, 3.2716e-04, 6.5711e-03, 1.7862e-02, 2.0101e-09]])\n",
            "tensor(2.0000)\n",
            "tensor([[-8.0284e+00, -7.0284e+00, -6.0284e+00, -5.0284e+00, -4.0284e+00,\n",
            "         -2.8373e-02],\n",
            "        [-1.1003e+02, -2.5072e-02, -8.0251e+00, -5.0251e+00, -4.0251e+00,\n",
            "         -2.0025e+01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Et_PuDhGmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjYwimamP-TU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9d3aade-8e00-4905-8309-8b23e31d97b4"
      },
      "source": [
        "# Just in order to get the shape of images\n",
        "next(iter(train_loader))[0].shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CftWhyC-IVIs",
        "colab_type": "text"
      },
      "source": [
        "### Get summary of model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsIdedGqhGMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a1a02abd-487f-444f-b308-81c70823efc5"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(net, input_size=(1, 28, 28)) # 1, 1, 32, 32"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 4, 26, 26]              40\n",
            "            Conv2d-2            [-1, 8, 24, 24]             296\n",
            "            Linear-3                  [-1, 100]         460,900\n",
            "            Linear-4                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 462,246\n",
            "Trainable params: 462,246\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.06\n",
            "Params size (MB): 1.76\n",
            "Estimated Total Size (MB): 1.82\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTUg7lFgIYT5",
        "colab_type": "text"
      },
      "source": [
        "### Define Loss and Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ-k7y5AhGIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function:\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# Define optimizer: \n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n68t0yACU7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "264e1bd3-b41e-428d-d230-c8970fba4538"
      },
      "source": [
        "# Just to ckeck that before training it is 10% accuracy:\n",
        "x_test, y_test = next(iter(test_loader))\n",
        "\n",
        "outputs_test = net(x_test)\n",
        "_, predicted = torch.max(outputs_test, 1)\n",
        "predicted\n",
        "(predicted == y_test).sum().item() / 64"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCQW_mABIvsK",
        "colab_type": "text"
      },
      "source": [
        "### Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CgFFqDBhGAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "95b8570d-d661-4b6a-ef46-1fcfb6683cff"
      },
      "source": [
        "for epoch in range(2): # epochs loop\n",
        "  net.train() # for enable Dropout. When net.eval() => Dropout is disabled\n",
        "  running_loss = 0.0\n",
        "  j = 0\n",
        "  \n",
        "  for data, labels in train_loader: # loop over data\n",
        "    j += 1\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs = net(data)\n",
        "    # _, predicted = torch.max(outputs, 1)\n",
        "    \n",
        "    # print(outputs.shape)\n",
        "    # print(labels.shape)\n",
        "    \n",
        "    loss = criterion(outputs, labels) # CrossEntropy\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if j % 200 == 199:    # print every 2000 mini-batches\n",
        "        print('[%d, %5d] loss: %.3f' %\n",
        "              (epoch + 1, j + 1, running_loss / 2000))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 0.160\n",
            "[1,   400] loss: 0.038\n",
            "[1,   600] loss: 0.029\n",
            "[1,   800] loss: 0.025\n",
            "[2,   200] loss: 0.020\n",
            "[2,   400] loss: 0.018\n",
            "[2,   600] loss: 0.017\n",
            "[2,   800] loss: 0.016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-afQrnfQSBu",
        "colab_type": "text"
      },
      "source": [
        "### Check on test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IulcaxJ-3iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_quality(test_loader):\n",
        "  accuracy_list = []\n",
        "  for x_test, y_test in test_loader:\n",
        "    outputs_test = net(x_test)\n",
        "    _, predicted = torch.max(outputs_test, 1)\n",
        "    temp_acc = (predicted == y_test).sum().item() / 64\n",
        "    accuracy_list.append(temp_acc)\n",
        "  return accuracy_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgZFe_nu_KNI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "643497c2-8d17-4302-d954-97342069e1cc"
      },
      "source": [
        "check_quality(test_loader)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.953125,\n",
              " 0.9375,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 1.0,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 1.0,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 1.0,\n",
              " 0.90625,\n",
              " 0.984375,\n",
              " 0.90625,\n",
              " 1.0,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.921875,\n",
              " 0.953125,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.921875,\n",
              " 0.9375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.921875,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 1.0,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.921875,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 1.0,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 1.0,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 1.0,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.90625,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 1.0,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 1.0,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.890625,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 0.90625,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.921875,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.953125,\n",
              " 0.9375,\n",
              " 0.96875,\n",
              " 0.984375,\n",
              " 0.953125,\n",
              " 0.984375,\n",
              " 0.984375,\n",
              " 0.9375,\n",
              " 0.984375,\n",
              " 0.96875,\n",
              " 0.96875,\n",
              " 0.9375,\n",
              " 0.953125,\n",
              " 0.234375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtN9WkH7_bcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0f59516-74b2-481d-9796-1e83c0a63e6c"
      },
      "source": [
        "acc_list = check_quality(test_loader)\n",
        "sum(acc_list) / len(acc_list)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9522292993630573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcqksyvHI4Yc",
        "colab_type": "text"
      },
      "source": [
        "### Same for one batch of images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ggDXQGGux8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test, y_test = next(iter(test_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfU_P8DcQVaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "097bff17-e079-47da-972b-27aac988c453"
      },
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XlvVdMKFvvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1da66088-5455-45c4-f618-55b61b548e7c"
      },
      "source": [
        "outputs_test = net(x_test)\n",
        "outputs_test"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-8.7920e+00, -1.2415e+01, -3.7741e+00, -2.0074e+00, -3.7990e+00,\n",
              "         -6.2691e+00, -9.1518e+00, -4.7923e+00, -2.9622e-01, -2.7146e+00],\n",
              "        [-1.6456e+01, -1.7466e+01, -6.0714e+00, -1.0595e+01, -1.3641e+01,\n",
              "         -1.5363e+01, -2.1295e+01, -2.5913e-03, -1.0887e+01, -8.3572e+00],\n",
              "        [-2.5262e+01, -2.1352e+01, -9.9324e+00, -9.7488e+00, -1.9490e+01,\n",
              "         -2.1838e+01, -2.7233e+01, -1.1134e-04, -1.3094e+01, -1.2967e+01],\n",
              "        [-1.5652e+01, -1.3488e+01, -1.2040e+01, -1.0595e+01, -1.9812e+01,\n",
              "         -1.3047e+01, -2.1133e+01, -1.8829e+01, -3.6477e-05, -1.3241e+01],\n",
              "        [-1.2013e+01, -1.7937e+01, -1.6591e+01, -1.6937e+01, -1.5699e+01,\n",
              "         -2.2822e-03, -1.7981e+01, -6.9231e+00, -6.6544e+00, -1.5968e+01],\n",
              "        [-6.2207e-03, -1.0862e+01, -9.5617e+00, -1.2535e+01, -1.1582e+01,\n",
              "         -5.9140e+00, -6.2201e+00, -8.9278e+00, -7.7311e+00, -7.0856e+00],\n",
              "        [-2.0059e+01, -1.1619e+01, -7.4253e+00, -6.4105e+00, -9.2299e+00,\n",
              "         -1.3781e+01, -1.6518e+01, -3.4142e-03, -8.5985e+00, -7.0405e+00],\n",
              "        [-1.6551e+01, -2.3943e+01, -1.1185e+01, -9.9925e+00, -1.8860e+01,\n",
              "         -8.7299e+00, -2.5565e+01, -1.2261e+01, -2.3231e-04, -1.2007e+01],\n",
              "        [-1.4376e+01, -1.0852e+01, -4.7128e+00, -3.7163e+00, -1.4462e+01,\n",
              "         -1.3828e+01, -1.9308e+01, -3.4308e-02, -8.6933e+00, -8.3596e+00],\n",
              "        [-4.2295e+00, -1.5191e+01, -9.6499e+00, -1.5309e+01, -5.3514e+00,\n",
              "         -4.1852e+00, -3.5494e-02, -1.0928e+01, -8.8262e+00, -9.0133e+00],\n",
              "        [-6.5230e-02, -9.0331e+00, -3.6399e+00, -6.6587e+00, -9.1019e+00,\n",
              "         -4.4331e+00, -9.2149e+00, -4.4115e+00, -4.4984e+00, -8.8876e+00],\n",
              "        [-1.9063e+01, -1.5909e+01, -1.2757e+01, -1.3263e+01, -1.7761e-04,\n",
              "         -1.2086e+01, -1.1645e+01, -1.0487e+01, -1.0359e+01, -9.2224e+00],\n",
              "        [-1.9339e+01, -1.3197e+01, -1.4559e+01, -1.2892e+01, -7.3823e+00,\n",
              "         -1.3734e+01, -1.9615e+01, -6.8266e+00, -9.8015e+00, -1.7695e-03],\n",
              "        [-1.0652e+01, -1.2099e+01, -8.5549e+00, -2.8019e-03, -1.8959e+01,\n",
              "         -7.8111e+00, -2.0673e+01, -1.2864e+01, -6.1972e+00, -8.9234e+00],\n",
              "        [-4.0286e+00, -6.6959e+00, -6.9404e+00, -4.2587e+00, -7.4554e+00,\n",
              "         -4.1928e-02, -6.2968e+00, -6.0806e+00, -7.1406e+00, -6.5584e+00],\n",
              "        [-1.8307e+01, -1.6610e+01, -8.2326e+00, -9.0041e+00, -1.8353e+01,\n",
              "         -1.4231e+01, -2.2140e+01, -1.6785e-03, -1.3327e+01, -6.6563e+00],\n",
              "        [-1.5049e+01, -8.2979e+00, -1.2777e+01, -8.9854e+00, -4.1204e+00,\n",
              "         -8.2380e+00, -1.3231e+01, -7.4902e+00, -4.7935e+00, -2.6059e-02],\n",
              "        [-1.7817e+01, -4.0623e-03, -8.2644e+00, -8.6234e+00, -1.3806e+01,\n",
              "         -1.3290e+01, -1.3820e+01, -9.2032e+00, -5.6541e+00, -1.1610e+01],\n",
              "        [-1.9204e+01, -9.7369e+00, -9.2054e+00, -8.2437e+00, -9.9106e+00,\n",
              "         -9.2519e+00, -1.0108e+01, -1.6884e+01, -6.1076e-04, -1.3288e+01],\n",
              "        [-4.8421e-02, -1.0375e+01, -8.9173e+00, -3.7202e+00, -1.6661e+01,\n",
              "         -4.7975e+00, -1.4346e+01, -4.7618e+00, -5.2394e+00, -7.1725e+00],\n",
              "        [-1.4991e+01, -1.5591e+01, -1.0799e+01, -1.0836e+01, -2.0065e+01,\n",
              "         -8.3005e+00, -1.1297e+01, -2.2029e+01, -3.0143e-04, -1.7217e+01],\n",
              "        [-1.6086e+01, -2.4861e-03, -8.5929e+00, -8.0320e+00, -1.0954e+01,\n",
              "         -1.0365e+01, -1.0448e+01, -7.3402e+00, -6.7252e+00, -9.9960e+00],\n",
              "        [-1.3945e+01, -9.6104e+00, -8.1035e+00, -4.1746e+00, -4.5414e+00,\n",
              "         -5.3337e+00, -8.4762e+00, -5.4563e+00, -3.6492e+00, -6.3714e-02],\n",
              "        [-3.9582e+00, -1.3070e+01, -7.2818e+00, -1.5741e+01, -3.5268e+00,\n",
              "         -9.3969e+00, -5.1878e-02, -1.0750e+01, -1.1556e+01, -6.6797e+00],\n",
              "        [-1.5379e+01, -4.9508e-02, -6.8763e+00, -6.4323e+00, -1.2052e+01,\n",
              "         -1.1701e+01, -1.3418e+01, -5.0035e+00, -3.2526e+00, -8.2650e+00],\n",
              "        [-1.3585e+01, -1.4841e+01, -7.4144e+00, -7.3777e+00, -1.3528e+01,\n",
              "         -1.2135e+01, -1.8016e+01, -1.7379e-03, -9.9323e+00, -7.7021e+00],\n",
              "        [-2.3795e+01, -2.0553e+01, -1.4222e+01, -3.8581e-04, -1.9290e+01,\n",
              "         -8.1079e+00, -2.6168e+01, -2.0922e+01, -9.3884e+00, -1.5100e+01],\n",
              "        [-2.1809e+01, -2.3061e+01, -9.5816e+00, -1.0139e+01, -2.0074e+01,\n",
              "         -1.8736e+01, -2.8966e+01, -1.4185e-04, -1.2173e+01, -1.0479e+01],\n",
              "        [-7.8210e+00, -1.4810e+01, -8.4778e+00, -8.9381e+00, -4.0949e+00,\n",
              "         -8.7208e+00, -1.0370e+01, -5.3023e+00, -5.5171e+00, -2.6949e-02],\n",
              "        [-2.0791e+01, -8.7598e+00, -6.7652e-04, -7.7051e+00, -1.6959e+01,\n",
              "         -1.4553e+01, -1.3065e+01, -1.0727e+01, -1.0026e+01, -1.7854e+01],\n",
              "        [-4.2438e-05, -1.9953e+01, -1.7274e+01, -1.7721e+01, -2.5707e+01,\n",
              "         -1.0207e+01, -1.3901e+01, -1.2385e+01, -1.5548e+01, -1.5161e+01],\n",
              "        [-1.4174e+01, -1.2586e+01, -1.4789e+01, -1.3621e+00, -8.8662e+00,\n",
              "         -2.1157e+00, -1.7839e+01, -4.7127e+00, -6.3889e-01, -2.4495e+00],\n",
              "        [-5.4716e-05, -2.0585e+01, -1.6595e+01, -1.8232e+01, -2.0668e+01,\n",
              "         -1.1422e+01, -1.1341e+01, -1.3460e+01, -1.0666e+01, -1.1880e+01],\n",
              "        [-6.3413e-01, -1.0689e+01, -5.7625e+00, -3.9429e+00, -1.2897e+01,\n",
              "         -3.1464e+00, -1.1301e+01, -1.0243e+00, -5.9626e+00, -3.1604e+00],\n",
              "        [-1.7564e+01, -2.4300e+01, -1.7062e+01, -1.9984e+01, -1.5993e+01,\n",
              "         -8.7867e+00, -1.4763e+01, -2.4047e+01, -1.5341e-04, -1.6595e+01],\n",
              "        [-1.5826e+01, -1.1446e+01, -9.1376e+00, -4.0321e+00, -1.9862e+01,\n",
              "         -2.7857e-02, -1.1435e+01, -1.7254e+01, -4.6456e+00, -1.2680e+01],\n",
              "        [-1.5026e+01, -1.6775e+01, -1.7498e+01, -1.4922e+01, -1.6407e+01,\n",
              "         -3.8819e-04, -1.4566e+01, -1.8654e+01, -7.8575e+00, -1.7229e+01],\n",
              "        [-1.2852e+01, -9.7665e-03, -6.8618e+00, -6.7398e+00, -8.9115e+00,\n",
              "         -8.4716e+00, -1.0106e+01, -5.2077e+00, -7.1801e+00, -7.0521e+00],\n",
              "        [-9.9848e+00, -1.0465e+01, -9.9671e+00, -3.3448e+00, -1.1156e+01,\n",
              "         -2.0898e+00, -9.3929e+00, -1.2279e+01, -1.7405e-01, -7.5092e+00],\n",
              "        [-1.3935e+01, -1.7913e+01, -1.0459e+01, -4.1887e+00, -2.1333e+01,\n",
              "         -2.0728e-01, -1.9940e+01, -1.5159e+01, -1.7602e+00, -1.4179e+01],\n",
              "        [-1.6199e+01, -1.0698e+01, -1.0947e+01, -8.8227e+00, -1.6038e+01,\n",
              "         -7.0866e+00, -1.5307e+01, -1.6489e+01, -1.0487e-03, -1.0641e+01],\n",
              "        [-1.1807e+01, -6.9094e-03, -6.5595e+00, -7.5769e+00, -9.1027e+00,\n",
              "         -9.8519e+00, -9.8255e+00, -6.1147e+00, -6.0696e+00, -8.4738e+00],\n",
              "        [-1.1822e+01, -8.6957e+00, -6.4324e+00, -1.9655e+00, -2.2691e+01,\n",
              "         -1.5310e-01, -1.3698e+01, -1.5439e+01, -9.3471e+00, -1.4624e+01],\n",
              "        [-1.9924e+01, -1.7902e+01, -9.2119e+00, -1.3208e-04, -2.0167e+01,\n",
              "         -1.2191e+01, -2.3664e+01, -1.8362e+01, -1.0518e+01, -1.7004e+01],\n",
              "        [-1.6455e+01, -2.2195e+01, -1.0518e+01, -1.0802e+01, -1.8807e+01,\n",
              "         -1.3144e+01, -2.1570e+01, -7.0808e-05, -1.3559e+01, -1.0818e+01],\n",
              "        [-1.7774e+01, -1.4136e+01, -1.1320e+01, -1.0179e+01, -6.6694e+00,\n",
              "         -1.1901e+01, -1.3425e+01, -5.1740e+00, -9.7452e+00, -7.0734e-03],\n",
              "        [-9.8658e+00, -2.0286e+01, -6.8542e+00, -3.8993e+00, -1.7316e+01,\n",
              "         -1.1361e+01, -2.0742e+01, -2.1801e-02, -1.2851e+01, -8.5769e+00],\n",
              "        [-4.3157e+00, -1.0851e+01, -8.8370e+00, -7.4366e+00, -1.5749e+01,\n",
              "         -8.6481e+00, -1.2210e+01, -1.0946e+01, -1.5074e-02, -7.3354e+00],\n",
              "        [-1.5254e+01, -1.9211e+01, -5.4376e+00, -6.5859e+00, -1.6453e+01,\n",
              "         -1.6305e+01, -2.0833e+01, -5.7945e-03, -1.0185e+01, -1.1526e+01],\n",
              "        [-1.5238e+01, -1.6064e+01, -9.4089e+00, -2.4161e-04, -1.6454e+01,\n",
              "         -1.1185e+01, -2.2474e+01, -1.0645e+01, -9.4109e+00, -1.0136e+01],\n",
              "        [-1.5506e+01, -1.0678e+01, -1.1379e+01, -4.0233e+00, -5.3304e+00,\n",
              "         -5.5639e+00, -1.2950e+01, -5.3797e+00, -3.6171e+00, -5.9831e-02],\n",
              "        [-1.7971e+01, -1.1670e+01, -1.2338e+01, -3.0456e-03, -1.7433e+01,\n",
              "         -8.9400e+00, -2.1745e+01, -2.0074e+01, -5.8446e+00, -1.3407e+01],\n",
              "        [-1.6632e+01, -1.0987e+01, -7.7909e+00, -1.0665e+01, -1.2023e+01,\n",
              "         -9.2973e+00, -6.7535e+00, -1.8999e+01, -1.7206e-03, -1.3880e+01],\n",
              "        [-1.0207e+01, -6.1445e+00, -6.2136e+00, -8.2185e-02, -9.1925e+00,\n",
              "         -5.0975e+00, -1.1588e+01, -6.0053e+00, -4.8171e+00, -2.8484e+00],\n",
              "        [-1.1790e+01, -1.8773e+01, -1.0230e+01, -1.2615e+01, -1.5709e-03,\n",
              "         -9.8174e+00, -7.3113e+00, -1.0517e+01, -8.0317e+00, -7.7106e+00],\n",
              "        [-1.2862e+01, -1.9646e+01, -6.9918e+00, -6.3646e+00, -1.9412e+01,\n",
              "         -1.2282e+01, -2.1549e+01, -2.8059e-03, -1.4201e+01, -8.7828e+00],\n",
              "        [-1.9056e+01, -1.7062e+01, -1.5432e+01, -1.3130e+01, -2.2978e+01,\n",
              "         -8.1062e-06, -1.3176e+01, -2.3788e+01, -1.2443e+01, -1.8358e+01],\n",
              "        [-1.8819e+01, -2.0041e+01, -9.5367e-06, -1.1761e+01, -2.2777e+01,\n",
              "         -2.1116e+01, -1.5969e+01, -2.5483e+01, -1.3331e+01, -2.5499e+01],\n",
              "        [-1.8221e+01, -1.2340e+01, -1.3302e+01, -8.8146e+00, -6.0820e+00,\n",
              "         -1.0734e+01, -1.6596e+01, -6.5690e+00, -1.1132e+01, -3.8853e-03],\n",
              "        [-1.5668e+01, -4.5600e-03, -8.7264e+00, -9.4245e+00, -1.3378e+01,\n",
              "         -9.9839e+00, -9.4328e+00, -9.0893e+00, -5.5067e+00, -1.1937e+01],\n",
              "        [-6.4835e+00, -1.5085e+01, -5.8954e+00, -1.1343e+01, -1.3487e-01,\n",
              "         -7.9119e+00, -2.9052e+00, -5.5731e+00, -3.0017e+00, -4.3224e+00],\n",
              "        [-6.1272e-05, -2.0457e+01, -1.0073e+01, -1.3304e+01, -2.9359e+01,\n",
              "         -1.2610e+01, -1.9763e+01, -1.2300e+01, -1.1699e+01, -1.3691e+01],\n",
              "        [-1.5347e+01, -2.6230e-03, -7.7650e+00, -9.2849e+00, -1.2186e+01,\n",
              "         -1.0292e+01, -9.5021e+00, -7.9489e+00, -6.4224e+00, -1.1448e+01],\n",
              "        [-1.4694e+01, -1.5203e-03, -8.0941e+00, -1.0395e+01, -1.1513e+01,\n",
              "         -1.0730e+01, -9.3763e+00, -8.5824e+00, -7.0536e+00, -1.1142e+01]],\n",
              "       grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6jWumXRuyAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "28802f21-39b6-4637-f3b3-811c95771805"
      },
      "source": [
        "_, predicted = torch.max(outputs_test, 1)\n",
        "predicted"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8, 7, 7, 8, 5, 0, 7, 8, 7, 6, 0, 4, 9, 3, 5, 7, 9, 1, 8, 0, 8, 1, 9, 6,\n",
              "        1, 7, 3, 7, 9, 2, 0, 8, 0, 0, 8, 5, 5, 1, 8, 5, 8, 1, 5, 3, 7, 9, 7, 8,\n",
              "        7, 3, 9, 3, 8, 3, 4, 7, 5, 2, 9, 1, 4, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPtUq17xHShl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a3b8736c-642f-4326-9514-166a5ec3358a"
      },
      "source": [
        "# Show image\n",
        "%matplotlib inline \n",
        "plt.imshow(x_test[1].numpy().squeeze(), interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBShB9IivADSRF+ICnCDyRF+IGk/h+u5CSdlu9JPwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAPkkEpDIllg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "120c6774-3d62-407c-9a85-5dce3cfc1444"
      },
      "source": [
        "(predicted == y_test).sum().item() / 64"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.984375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1f6b1-VImpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}